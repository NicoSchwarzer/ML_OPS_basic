{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5-E8iQSlF5H"
      },
      "source": [
        "# Model Serving through APIs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXtjQVNPlKl0"
      },
      "source": [
        "## API \n",
        "\n",
        "- only calling API through HTTP requests to obtain results from ML Pipeline\n",
        "\n",
        "Most important HTTP methods:\n",
        "\n",
        "- get\n",
        "- post: create a resource\n",
        "- put: update a resource\n",
        "- patch: partially update a resource\n",
        "- delete: delete a resource\n",
        "\n",
        "Status Codes:\n",
        "- 2xxx: success\n",
        "- 3xxx: redirect\n",
        "- 4xxx: client error\n",
        "- 5xxx: server error\n",
        "\n",
        "In Python through libraries such as Django/Flask/FastAPI (latter has best performance). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastapi\n",
            "  Using cached fastapi-0.86.0-py3-none-any.whl (55 kB)\n",
            "Collecting starlette==0.20.4\n",
            "  Using cached starlette-0.20.4-py3-none-any.whl (63 kB)\n",
            "Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
            "  Downloading pydantic-1.10.2-cp39-cp39-win_amd64.whl (2.1 MB)\n",
            "     ---------------------------------------- 2.1/2.1 MB 3.2 MB/s eta 0:00:00\n",
            "Collecting anyio<5,>=3.4.0\n",
            "  Using cached anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in c:\\users\\nico\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from starlette==0.20.4->fastapi) (4.0.1)\n",
            "Collecting typing-extensions>=3.10.0\n",
            "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\nico\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi) (3.3)\n",
            "Installing collected packages: typing-extensions, sniffio, pydantic, anyio, starlette, fastapi\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.0.1\n",
            "    Uninstalling typing_extensions-4.0.1:\n",
            "      Successfully uninstalled typing_extensions-4.0.1\n",
            "Successfully installed anyio-3.6.2 fastapi-0.86.0 pydantic-1.10.2 sniffio-1.3.0 starlette-0.20.4 typing-extensions-4.4.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install uvicorn\n",
        "!pip install fastapi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M6b8Hh0WnV8N"
      },
      "outputs": [],
      "source": [
        "import uvicorn\n",
        "from fastapi import FastAPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GflToaRBnq5W"
      },
      "outputs": [],
      "source": [
        "# init the API\n",
        "\n",
        "app = FastAPI()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wK3dMwFQn1V0"
      },
      "outputs": [],
      "source": [
        "@app.get(\"/\")\n",
        "def home():\n",
        "  return{\"Hello\": \"World\"}\n",
        "\n",
        "if __name__ == \"main\":\n",
        "  uvicorn.run(\"hello_world_fastapi:app\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# or:\n",
        "@app.get(\"/\")\n",
        "def home():\n",
        "  return{\"Hello\": \"World\"}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(\"hello_world:app\")\n",
        "    \n",
        "#app, host = \"127.0.0.1\", port = 8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.get(\"/\")\n",
        "def home():\n",
        "  return{\"Hello\":\"GET\"} # GET decoratpr\n",
        "\n",
        "@app.post(\"/\")\n",
        "def home_post():\n",
        "  return{\"Hello\":\"POST\"} # POST decorator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "## query parameters:\n",
        "\n",
        "@app.get(\"/employee\") # for each employye -> the department\n",
        "def home(department:str): # indicating data type\n",
        "    return{\"department\": department}\n",
        "\n",
        "\n",
        "## path parameters - id sub-path \n",
        "\n",
        "@app.get(\"/employee/{id}\")\n",
        "def gome(id:int): # # indicating data type\n",
        "    return{\"id\":id}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-> check example_FastAPI_1.py file!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post/Swagger/Pydantic with FastAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "again, check out the example File - it's rather easy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic ML API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ccheeck out the Model_scikit and the app_scikit py files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# now using the API\n",
        "\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Response [404]>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = requests.get(\"http://127.0.0.2:8000/\") ## will not yield anything as this API does not serve GET requests\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'{\"prediction\":\"virginica\",\"probability\":0.9}'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# but this will :))\n",
        "new_measurement = {\n",
        "    'sepal_length': 5.7,\n",
        "    'sepal_width': 3.1,\n",
        "    'petal_length': 4.9,\n",
        "    'petal_width': 2.2\n",
        "}\n",
        "\n",
        "response = requests.post('http://127.0.0.2:8000/predict', json=new_measurement)\n",
        "print(response.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Now taking it global (not just through the localhost option)\n",
        "\n",
        "After havign executed all steps here (https://www.geeksforgeeks.org/how-to-host-a-local-server-globally-for-more-than-one-system/),\n",
        "the gobal API is now available at: https://54b9-184-82-25-61.ap.ngrok.io/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'{\"prediction\":\"virginica\",\"probability\":0.9}'\n"
          ]
        }
      ],
      "source": [
        "## trying again:\n",
        "\n",
        "global_url = 'https://54b9-184-82-25-61.ap.ngrok.io/'\n",
        "\n",
        "new_measurement = {\n",
        "    'sepal_length': 5.7,\n",
        "    'sepal_width': 3.1,\n",
        "    'petal_length': 4.9,\n",
        "    'petal_width': 2.2\n",
        "}\n",
        "\n",
        "response = requests.post(str(global_url +  \"predict\"), json=new_measurement)\n",
        "print(response.content)\n",
        "\n",
        "\n",
        "## GEIL !!!\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "e63cf95f9ea0e246828388f52fcc64bcfae4879cee3720bf2af2efa5e72059a6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
